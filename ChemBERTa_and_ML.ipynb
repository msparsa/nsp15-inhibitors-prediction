{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_U_Me_rMqrhG",
        "outputId": "9f1d8040-79db-4643-cccc-e45ae1d97b8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizer, RobertaTokenizer,AutoTokenizer, AutoModelForMaskedLM,AutoModel\n",
        "import torch\n",
        "\n",
        "model_name = 'DeepChem/ChemBERTa-77M-MLM'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "chembert_model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
        "\n",
        "def get_bert_embeddings(smiles_strings):\n",
        "    encoded_input = tokenizer(smiles_strings, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = chembert_model(**encoded_input)\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :]  # Using the [CLS] token embedding from last hidden state\n",
        "    return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b_0GUZ_IqrhI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv('/home/parsa/smiles_classification/training_w_features.csv').sample(frac=1)\n",
        "val_data = pd.read_csv('/home/parsa/smiles_classification/validation_w_features.csv')#.rename({'RESULTS':'RESULT'},axis=1) #pd.read_csv('/home/parsa/smiles_classification/data_validation.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa_JCNEDqrhJ",
        "outputId": "3956e16c-3a7b-4ae3-dc26-52429bb6c2d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Molecular Weight</th>\n",
              "      <th>LogP</th>\n",
              "      <th>Number of Atoms</th>\n",
              "      <th>Number of Bonds</th>\n",
              "      <th>Number of Rings</th>\n",
              "      <th>Rotatable Bonds Count</th>\n",
              "      <th>Hydrogen Bond Donors</th>\n",
              "      <th>Hydrogen Bond Acceptors</th>\n",
              "      <th>Number of Stereocenters</th>\n",
              "      <th>Topological Polar Surface Area (TPSA)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Results</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SMILES  Molecular Weight  LogP  Number of Atoms  Number of Bonds  \\\n",
              "Results                                                                     \n",
              "0           203               203   203              203              203   \n",
              "1           203               203   203              203              203   \n",
              "\n",
              "         Number of Rings  Rotatable Bonds Count  Hydrogen Bond Donors  \\\n",
              "Results                                                                 \n",
              "0                    203                    203                   203   \n",
              "1                    203                    203                   203   \n",
              "\n",
              "         Hydrogen Bond Acceptors  Number of Stereocenters  \\\n",
              "Results                                                     \n",
              "0                            203                      203   \n",
              "1                            203                      203   \n",
              "\n",
              "         Topological Polar Surface Area (TPSA)  \n",
              "Results                                         \n",
              "0                                          203  \n",
              "1                                          203  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.groupby('Results').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "19FTBJivqrhJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def process_X_data(smiles, features):\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    embeddings = get_bert_embeddings(smiles).numpy()\n",
        "    combined_features = np.concatenate((embeddings, features), axis=1)\n",
        "    return scaler.fit_transform(combined_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XTNX9DhEqrhJ",
        "outputId": "29ed7ff8-4b04-40f7-93cc-9bd25f1d975f"
      },
      "outputs": [],
      "source": [
        "feature_columns = ['Molecular Weight', 'LogP', 'Number of Atoms',\n",
        "       'Number of Bonds', 'Number of Rings', 'Rotatable Bonds Count',\n",
        "       'Hydrogen Bond Donors', 'Hydrogen Bond Acceptors',\n",
        "       'Number of Stereocenters', 'Topological Polar Surface Area (TPSA)'] # Add all your feature column names\n",
        "\n",
        "\n",
        "train_x = process_X_data(train_data.SMILES.tolist(), train_data[feature_columns].values )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DD0U0zaWqrhJ",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'classifier': GradientBoostingClassifier(), 'classifier__learning_rate': 0.01, 'classifier__n_estimators': 100, 'scaler': MinMaxScaler()}\n",
            "Best cross-validated score: 0.7302871283306066\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB  # Gaussian for continuous features, Multinomial for discrete\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from functools import partial\n",
        "\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "\n",
        "# Define a pipeline if scaling is needed (e.g., for SVM or KNN)\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Define parameter grids for different classifiers\n",
        "param_grid = [\n",
        "    {'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "     'classifier': [SVC()],\n",
        "     'classifier__C': [0.1, 1, 10],\n",
        "     'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
        "    {'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "     'classifier': [RandomForestClassifier()],\n",
        "     'classifier__n_estimators': [10, 50, 100],\n",
        "     'classifier__max_features': ['sqrt', 'log2']},\n",
        "    {'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "     'classifier': [GradientBoostingClassifier()],\n",
        "     'classifier__n_estimators': [50, 100, 150],\n",
        "     'classifier__learning_rate': [0.01, 0.1, 0.2]},\n",
        "    {'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "     'classifier': [LogisticRegression(max_iter=1000)],\n",
        "     'classifier__C': [0.1, 1, 10]},\n",
        "    {'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "     'classifier': [KNeighborsClassifier()],\n",
        "     'classifier__n_neighbors': [3, 5, 7, 9, 11, 13]},\n",
        "    {'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "     'classifier': [DecisionTreeClassifier()],\n",
        "     'classifier__criterion': ['gini', 'entropy'],\n",
        "     'classifier__max_depth': [None, 10, 20],\n",
        "     'classifier__min_samples_split': [2, 10]},\n",
        "    {'scaler': [StandardScaler()],\n",
        "     'classifier': [GaussianNB()]},\n",
        "    {'scaler': [MinMaxScaler()],  # Ensure non-negative input for MultinomialNB\n",
        "     'classifier': [MultinomialNB()],\n",
        "     'classifier__alpha': [0.1, 1.0, 10.0]},\n",
        "]\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'recall': make_scorer(recall_score, zero_division=0),\n",
        "    'f1': make_scorer(f1_score, zero_division=0),\n",
        "    'precision': make_scorer(precision_score, zero_division=0)\n",
        "}\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    pipe,\n",
        "    param_grid,\n",
        "    scoring=scoring,\n",
        "    refit='precision',  # Choose one metric to use for refitting the best model\n",
        "    cv=10,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Assuming X_train, y_train are your data prepared earlier\n",
        "grid_search.fit(train_x,  train_data.Results)\n",
        "\n",
        "# Best model after grid search\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validated score:\", grid_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h21PVjIxqrhK",
        "outputId": "355ee572-547c-4cad-f4dd-7ab88da09bc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_classifier</th>\n",
              "      <th>mean_test_precision</th>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <th>mean_test_recall</th>\n",
              "      <th>mean_test_f1</th>\n",
              "      <th>rank_test_precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>GradientBoostingClassifier()</td>\n",
              "      <td>0.730287</td>\n",
              "      <td>0.726463</td>\n",
              "      <td>0.728810</td>\n",
              "      <td>0.725804</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RandomForestClassifier()</td>\n",
              "      <td>0.691450</td>\n",
              "      <td>0.672622</td>\n",
              "      <td>0.635714</td>\n",
              "      <td>0.660238</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVC()</td>\n",
              "      <td>0.676809</td>\n",
              "      <td>0.689451</td>\n",
              "      <td>0.743095</td>\n",
              "      <td>0.705566</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>DecisionTreeClassifier()</td>\n",
              "      <td>0.664654</td>\n",
              "      <td>0.662195</td>\n",
              "      <td>0.665476</td>\n",
              "      <td>0.663622</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>0.664570</td>\n",
              "      <td>0.669695</td>\n",
              "      <td>0.699286</td>\n",
              "      <td>0.678140</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>0.617277</td>\n",
              "      <td>0.615549</td>\n",
              "      <td>0.605476</td>\n",
              "      <td>0.606917</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>KNeighborsClassifier()</td>\n",
              "      <td>0.597963</td>\n",
              "      <td>0.598232</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.607355</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>GaussianNB()</td>\n",
              "      <td>0.595014</td>\n",
              "      <td>0.603415</td>\n",
              "      <td>0.639762</td>\n",
              "      <td>0.612426</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     param_classifier  mean_test_precision  \\\n",
              "39       GradientBoostingClassifier()             0.730287   \n",
              "26           RandomForestClassifier()             0.691450   \n",
              "14                              SVC()             0.676809   \n",
              "84           DecisionTreeClassifier()             0.664654   \n",
              "55  LogisticRegression(max_iter=1000)             0.664570   \n",
              "97                    MultinomialNB()             0.617277   \n",
              "61             KNeighborsClassifier()             0.597963   \n",
              "96                       GaussianNB()             0.595014   \n",
              "\n",
              "    mean_test_accuracy  mean_test_recall  mean_test_f1  rank_test_precision  \n",
              "39            0.726463          0.728810      0.725804                    1  \n",
              "26            0.672622          0.635714      0.660238                    7  \n",
              "14            0.689451          0.743095      0.705566                   10  \n",
              "84            0.662195          0.665476      0.663622                   16  \n",
              "55            0.669695          0.699286      0.678140                   17  \n",
              "97            0.615549          0.605476      0.606917                   70  \n",
              "61            0.598232          0.620000      0.607355                   74  \n",
              "96            0.603415          0.639762      0.612426                   75  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = grid_search.cv_results_\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Convert results to a DataFrame for easier handling and visualization\n",
        "df_results = pd.DataFrame(results)\n",
        "# selected_columns = [col for col in df_results.columns if 'param_' in col or 'test_accuracy' in col or 'test_precision' in col]\n",
        "# df_results = df_results[selected_columns]\n",
        "display(df_results[['param_classifier','mean_test_precision',\t'mean_test_accuracy','mean_test_recall',\t'mean_test_f1',\t'rank_test_precision']].sort_values('rank_test_precision').drop_duplicates('param_classifier'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.730769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.612245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.641509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.654545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.488889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.549020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Model  Accuracy  Precision  Recall  F1 Score\n",
              "2  GradientBoostingClassifier      0.72   0.703704    0.76  0.730769\n",
              "3          LogisticRegression      0.62   0.625000    0.60  0.612245\n",
              "4        KNeighborsClassifier      0.62   0.607143    0.68  0.641509\n",
              "5      DecisionTreeClassifier      0.62   0.600000    0.72  0.654545\n",
              "6                  GaussianNB      0.60   0.592593    0.64  0.615385\n",
              "0                         SVC      0.58   0.583333    0.56  0.571429\n",
              "1      RandomForestClassifier      0.54   0.550000    0.44  0.488889\n",
              "7               MultinomialNB      0.54   0.538462    0.56  0.549020"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extract best models for each classifier type\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "best_models = {}\n",
        "val_data = pd.read_csv('/home/parsa/smiles_classification/validation_w_features.csv')#.rename({'RESULTS':'RESULT'},axis=1) #pd.read_csv('/home/parsa/smiles_classification/data_validation.csv')\n",
        "val_x = process_X_data(val_data.SMILES.tolist(), val_data[feature_columns].values )\n",
        "\n",
        "for classifier_name in [\"SVC\", \"RandomForestClassifier\", \"GradientBoostingClassifier\", \n",
        "                        \"LogisticRegression\", \"KNeighborsClassifier\", \n",
        "                        \"DecisionTreeClassifier\", \"GaussianNB\", \"MultinomialNB\"]:\n",
        "    best_result = results[results['param_classifier'].apply(lambda x: x.__class__.__name__) == classifier_name].iloc[0]\n",
        "    best_params = best_result['params']\n",
        "    \n",
        "    # Recreate the pipeline with the best parameters\n",
        "    best_pipeline = Pipeline([\n",
        "        ('scaler', best_params['scaler']),\n",
        "        ('classifier', best_params['classifier'])\n",
        "    ])\n",
        "    best_pipeline.set_params(**{k: v for k, v in best_params.items() if k not in ['scaler', 'classifier']})\n",
        "    \n",
        "    # Store the model for validation\n",
        "    best_models[classifier_name] = best_pipeline\n",
        "\n",
        "# Validation step\n",
        "validation_results = []\n",
        "for classifier_name, model in best_models.items():\n",
        "    model.fit(train_x, train_data.Results)  # Refit on the training data\n",
        "    y_pred = model.predict(val_x)\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(val_data.RESULT, y_pred)\n",
        "    precision = precision_score(val_data.RESULT, y_pred, zero_division=0)\n",
        "    recall = recall_score(val_data.RESULT, y_pred, zero_division=0)\n",
        "    f1 = f1_score(val_data.RESULT, y_pred, zero_division=0)\n",
        "    \n",
        "    # Append results to the list\n",
        "    validation_results.append({\n",
        "        \"Model\": classifier_name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    })\n",
        "\n",
        "# Convert the results to a dataframe\n",
        "validation_results_df = pd.DataFrame(validation_results).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "# Display the dataframe\n",
        "display(validation_results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "p2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
